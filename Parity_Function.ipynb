{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx2hhdNUTyiH"
      },
      "source": [
        "# **The Parity function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qia1HWGkT6TK"
      },
      "source": [
        "## **1 : Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdtFR3tPTs2i",
        "outputId": "44288891-4a1b-4283-ad27-3cfbf2f1ea6b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# this 'device' will be used for training our model\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ate-GGQFUCuM"
      },
      "source": [
        "## **2 : Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahEa7_LzUAFw"
      },
      "source": [
        "def gen_bits(bit):\n",
        "    x = np.random.random_integers(bit-1, size=np.random.randint(bit))\n",
        "    t = torch.zeros(bit,1)\n",
        "    for i in x:\n",
        "        t[i][0] = 1\n",
        "    parity = int(t.sum().item()%2 == 1)\n",
        "    return t, parity\n",
        "\n",
        "def gen_data(size, bit=64):\n",
        "    data = []\n",
        "    for i in range(size):\n",
        "        data.append(gen_bits(bit))\n",
        "    return data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvskyCLOUf08",
        "outputId": "c8163be8-e216-4168-dd83-9cf20f75caf4"
      },
      "source": [
        "data_2000 = gen_data(2000) #dataset for 2000 size\n",
        "data_5000 = gen_data(5000) #dataset for 5000 size\n",
        "data_test = gen_data(800) #test dataset for both 2000 and 5000 size data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: This function is deprecated. Please call randint(1, 63 + 1) instead\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW9BDwKcUoKn"
      },
      "source": [
        "#Converting list to torch tensors\n",
        "train_loader_2000 = torch.utils.data.DataLoader(data_2000, batch_size=32, shuffle=True)\n",
        "train_loader_5000 = torch.utils.data.DataLoader(data_5000, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=800, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC2mzyOsVlNo"
      },
      "source": [
        "## **3 : Fully Connected Neural Network for the Parity dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSFquFP6VtQd"
      },
      "source": [
        "### Helper functions for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ZqlUJoVagU"
      },
      "source": [
        "# function to count number of parameters\n",
        "def get_n_params(model):\n",
        "    np=0\n",
        "    for p in list(model.parameters()):\n",
        "        np += p.nelement()\n",
        "    return np\n",
        "\n",
        "accuracy_list = []\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# we pass a model object to this trainer, and it trains this model for one epoch\n",
        "def train(epoch, model, print_set = 20):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # send to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data).squeeze()\n",
        "        loss = criterion(output, target.type(torch.float))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.round(output)\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
        "    accuracy = 100. * correct / len(train_loader.dataset)\n",
        "    print(\"Epoch:\",epoch,\"Training accuracy: \",accuracy,\"%\")\n",
        "            \n",
        "def test(model):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        # send to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        output = model(data).squeeze()\n",
        "        test_loss += criterion(output, target.type(torch.float)).sum().item() # sum up batch loss\n",
        "        pred = torch.round(output)\n",
        "        # pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    accuracy_list.append(accuracy)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        accuracy))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys8KpII0WRGo"
      },
      "source": [
        "### Defining the Fully Connected Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmZarak0WISb"
      },
      "source": [
        "class FC2Layer(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(FC2Layer, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,32), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32,16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, output_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        return self.network(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-cqyEvhWbUN"
      },
      "source": [
        "### Train the Network for 2000 size data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joY0tGG1WSxs",
        "outputId": "378a04b0-3ebd-400a-b233-fe7c13b5849a"
      },
      "source": [
        "input_size = 64\n",
        "output_size = 1\n",
        "print(\"Training on \", device)\n",
        "model_fnn = FC2Layer(input_size, output_size)\n",
        "model_fnn.to(device)\n",
        "optimizer = optim.Adam(model_fnn.parameters())\n",
        "print('Number of parameters: {}\\n'.format(get_n_params(model_fnn)))\n",
        "\n",
        "train_loader = train_loader_2000\n",
        "\n",
        "for epoch in range(20):\n",
        "    train(epoch, model_fnn)\n",
        "    test(model_fnn)\n",
        "    print('\\n')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on  cpu\n",
            "Number of parameters: 6785\n",
            "\n",
            "Epoch: 0 Training accuracy:  48.45 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 422/800 (53%)\n",
            "\n",
            "\n",
            "Epoch: 1 Training accuracy:  51.9 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 414/800 (52%)\n",
            "\n",
            "\n",
            "Epoch: 2 Training accuracy:  51.85 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 414/800 (52%)\n",
            "\n",
            "\n",
            "Epoch: 3 Training accuracy:  52.95 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 421/800 (53%)\n",
            "\n",
            "\n",
            "Epoch: 4 Training accuracy:  57.25 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 421/800 (53%)\n",
            "\n",
            "\n",
            "Epoch: 5 Training accuracy:  60.75 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 420/800 (52%)\n",
            "\n",
            "\n",
            "Epoch: 6 Training accuracy:  63.15 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 421/800 (53%)\n",
            "\n",
            "\n",
            "Epoch: 7 Training accuracy:  65.5 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 424/800 (53%)\n",
            "\n",
            "\n",
            "Epoch: 8 Training accuracy:  69.75 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 424/800 (53%)\n",
            "\n",
            "\n",
            "Epoch: 9 Training accuracy:  75.65 %\n",
            "Test set: Average loss: 0.0010, Accuracy: 427/800 (53%)\n",
            "\n",
            "\n",
            "Epoch: 10 Training accuracy:  78.25 %\n",
            "Test set: Average loss: 0.0011, Accuracy: 430/800 (54%)\n",
            "\n",
            "\n",
            "Epoch: 11 Training accuracy:  82.65 %\n",
            "Test set: Average loss: 0.0012, Accuracy: 419/800 (52%)\n",
            "\n",
            "\n",
            "Epoch: 12 Training accuracy:  83.7 %\n",
            "Test set: Average loss: 0.0013, Accuracy: 427/800 (53%)\n",
            "\n",
            "\n",
            "Epoch: 13 Training accuracy:  86.75 %\n",
            "Test set: Average loss: 0.0016, Accuracy: 406/800 (51%)\n",
            "\n",
            "\n",
            "Epoch: 14 Training accuracy:  88.25 %\n",
            "Test set: Average loss: 0.0015, Accuracy: 420/800 (52%)\n",
            "\n",
            "\n",
            "Epoch: 15 Training accuracy:  90.35 %\n",
            "Test set: Average loss: 0.0016, Accuracy: 420/800 (52%)\n",
            "\n",
            "\n",
            "Epoch: 16 Training accuracy:  93.15 %\n",
            "Test set: Average loss: 0.0018, Accuracy: 413/800 (52%)\n",
            "\n",
            "\n",
            "Epoch: 17 Training accuracy:  94.0 %\n",
            "Test set: Average loss: 0.0019, Accuracy: 412/800 (52%)\n",
            "\n",
            "\n",
            "Epoch: 18 Training accuracy:  95.8 %\n",
            "Test set: Average loss: 0.0022, Accuracy: 420/800 (52%)\n",
            "\n",
            "\n",
            "Epoch: 19 Training accuracy:  95.35 %\n",
            "Test set: Average loss: 0.0022, Accuracy: 421/800 (53%)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXDHFmWkWuS4"
      },
      "source": [
        "### Train the Network for 5000 size data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7TR1KuSWWYc",
        "outputId": "cfe60e6a-8553-444b-ee57-b04b0b587c0f"
      },
      "source": [
        "input_size = 64\n",
        "output_size = 1\n",
        "print(\"Training on \", device)\n",
        "model_fnn = FC2Layer(input_size, output_size)\n",
        "model_fnn.to(device)\n",
        "optimizer = optim.Adam(model_fnn.parameters())\n",
        "print('Number of parameters: {}\\n'.format(get_n_params(model_fnn)))\n",
        "\n",
        "train_loader = train_loader_5000\n",
        "\n",
        "for epoch in range(20):\n",
        "    train(epoch, model_fnn)\n",
        "    test(model_fnn)\n",
        "    print('\\n')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on  cpu\n",
            "Number of parameters: 6785\n",
            "\n",
            "Epoch: 0 Training accuracy:  48.8 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 397/800 (50%)\n",
            "\n",
            "\n",
            "Epoch: 1 Training accuracy:  51.38 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 404/800 (50%)\n",
            "\n",
            "\n",
            "Epoch: 2 Training accuracy:  52.44 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 421/800 (53%)\n",
            "\n",
            "\n",
            "Epoch: 3 Training accuracy:  54.06 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 386/800 (48%)\n",
            "\n",
            "\n",
            "Epoch: 4 Training accuracy:  55.76 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 395/800 (49%)\n",
            "\n",
            "\n",
            "Epoch: 5 Training accuracy:  58.08 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 385/800 (48%)\n",
            "\n",
            "\n",
            "Epoch: 6 Training accuracy:  61.34 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 386/800 (48%)\n",
            "\n",
            "\n",
            "Epoch: 7 Training accuracy:  64.3 %\n",
            "Test set: Average loss: 0.0009, Accuracy: 404/800 (50%)\n",
            "\n",
            "\n",
            "Epoch: 8 Training accuracy:  67.76 %\n",
            "Test set: Average loss: 0.0010, Accuracy: 391/800 (49%)\n",
            "\n",
            "\n",
            "Epoch: 9 Training accuracy:  70.54 %\n",
            "Test set: Average loss: 0.0011, Accuracy: 396/800 (50%)\n",
            "\n",
            "\n",
            "Epoch: 10 Training accuracy:  72.1 %\n",
            "Test set: Average loss: 0.0011, Accuracy: 388/800 (48%)\n",
            "\n",
            "\n",
            "Epoch: 11 Training accuracy:  75.62 %\n",
            "Test set: Average loss: 0.0011, Accuracy: 392/800 (49%)\n",
            "\n",
            "\n",
            "Epoch: 12 Training accuracy:  76.6 %\n",
            "Test set: Average loss: 0.0012, Accuracy: 398/800 (50%)\n",
            "\n",
            "\n",
            "Epoch: 13 Training accuracy:  78.28 %\n",
            "Test set: Average loss: 0.0012, Accuracy: 391/800 (49%)\n",
            "\n",
            "\n",
            "Epoch: 14 Training accuracy:  80.18 %\n",
            "Test set: Average loss: 0.0014, Accuracy: 391/800 (49%)\n",
            "\n",
            "\n",
            "Epoch: 15 Training accuracy:  81.24 %\n",
            "Test set: Average loss: 0.0014, Accuracy: 391/800 (49%)\n",
            "\n",
            "\n",
            "Epoch: 16 Training accuracy:  82.76 %\n",
            "Test set: Average loss: 0.0015, Accuracy: 395/800 (49%)\n",
            "\n",
            "\n",
            "Epoch: 17 Training accuracy:  83.94 %\n",
            "Test set: Average loss: 0.0015, Accuracy: 403/800 (50%)\n",
            "\n",
            "\n",
            "Epoch: 18 Training accuracy:  85.44 %\n",
            "Test set: Average loss: 0.0016, Accuracy: 397/800 (50%)\n",
            "\n",
            "\n",
            "Epoch: 19 Training accuracy:  86.42 %\n",
            "Test set: Average loss: 0.0016, Accuracy: 395/800 (49%)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "589XZZaiW3a2"
      },
      "source": [
        "We can see that using both dataset we are getting traninig good accuracy, but getting only 50% test accuracy.\n",
        "We know there are $2^{64}$ possible combination of data points and we are only considering very few data points in our training.\n",
        "As it is not possible to take majority of data points in training, we will use manually created DNN for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZnKUrBFYNPK"
      },
      "source": [
        "## **4 : Manual Design of a Neural network for Parity dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztTfA1WIe-OV"
      },
      "source": [
        "Design of the Neural Network:\n",
        "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.5442&rep=rep1&type=pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIoJvScuWytM"
      },
      "source": [
        "class manual_nn():\n",
        "  def __init__(self, bit):\n",
        "    self.rows = bit + (bit//2)\n",
        "    self.bit = bit\n",
        "    self.W1 = self.initialize_W1()\n",
        "    self.b1 = self.initialize_b1()\n",
        "    self.W2 = self.initialize_W2()\n",
        "    self.b2 = torch.tensor(-0.5)\n",
        "\n",
        "  def forward(self, x, print = False):\n",
        "    if print:\n",
        "      print(\"x: \",x.shape)\n",
        "    a1 = torch.matmul(self.W1, x) + self.b1\n",
        "    if print:\n",
        "      print(\"a1: \",a1.shape)\n",
        "    h1 = self.steps(a1, self.rows)\n",
        "    if print:\n",
        "      print(\"h1: \",h1.shape)\n",
        "    a2 = torch.matmul(self.W2, h1) + self.b2\n",
        "    if print:\n",
        "      print(\"a2: \",a2.shape)\n",
        "    output = self.steps(a2, 1)\n",
        "    if print:\n",
        "      print(\"out: \",output.shape)\n",
        "    return output.item()\n",
        "\n",
        "  def initialize_W1(self):\n",
        "    rows = self.rows\n",
        "    cols = self.bit\n",
        "    temp = torch.zeros(rows,cols)\n",
        "    for i in range(cols):\n",
        "      temp[i][i] = 1\n",
        "    for i in range(cols, rows):\n",
        "      for j in range(cols):\n",
        "        temp[i][j] = 1\n",
        "    return temp\n",
        "\n",
        "  def initialize_b1(self):\n",
        "    rows = self.rows\n",
        "    temp = torch.zeros(rows,1)\n",
        "    t = 0.5\n",
        "    for i in range(self.bit, rows):\n",
        "      temp[i][0] = t-2\n",
        "      t -= 2 \n",
        "    return temp\n",
        "\n",
        "  def initialize_W2(self):\n",
        "    rows = self.rows\n",
        "    temp = torch.ones(1, rows)\n",
        "    for i in range(self.bit, rows):\n",
        "      temp[0][i] = -2\n",
        "    return temp\n",
        "\n",
        "  def steps(self, vect, size):\n",
        "    temp = torch.zeros(size,1)\n",
        "    for i in range(size):\n",
        "      if vect[i][0]>0:\n",
        "        temp[i][0] = 1\n",
        "    return temp\n",
        "  \n",
        "  def predict(self,x):\n",
        "    temp = torch.zeros(len(x))\n",
        "    for i in range(len(x)):\n",
        "      temp[i] = self.forward(x[i])\n",
        "    return temp\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKACNqFOY8Pz",
        "outputId": "49783809-7365-411c-e063-41d173a80f81"
      },
      "source": [
        "print(\"Training on \", device)\n",
        "model_manual = manual_nn(64)\n",
        "for images,labels in test_loader:\n",
        "  pred = model_manual.predict(images)\n",
        "print(\"Test set: Accuracy {}%\".format(int(sum(pred == labels)*100/len(labels))))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on  cpu\n",
            "Test set: Accuracy 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uI81OiVea-g"
      },
      "source": [
        "### Testing on large data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlbfQHGbehAj",
        "outputId": "e9155d6c-e763-4796-9d69-ec9d99c30410"
      },
      "source": [
        "data_test = gen_data(10000)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=800, shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: This function is deprecated. Please call randint(1, 63 + 1) instead\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3K5EAVvaVQ_",
        "outputId": "cf599b5d-1eb3-4624-8477-06b1521127f7"
      },
      "source": [
        "print(\"Training on \", device)\n",
        "model_manual = manual_nn(64)\n",
        "for images,labels in test_loader:\n",
        "  pred = model_manual.predict(images)\n",
        "print(\"Test set: Accuracy {}%\".format(int(sum(pred == labels)*100/len(labels))))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on  cpu\n",
            "Test set: Accuracy 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g0-SVjNes1p"
      },
      "source": [
        "Even on larger test data manual network is giving 100% accuracy"
      ]
    }
  ]
}